{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. divvy\n",
    "1. anaconda python\n",
    "1. aws account\n",
    "1. awscli\n",
    "1. installation: `conda --yes install s3fs pyarrow fastparquet tqdm seaborn holoviews`\n",
    "\n",
    "## trick list\n",
    "\n",
    "1. fullscreen everything\n",
    "1. command-tab\n",
    "1. divvy - command-shift-D\n",
    "1. conda set yes always true `conda config --set always_yes True`\n",
    "1. `! aws s3 ls` --> `pd.read_txt`\n",
    "1. write & submit reflow batch\n",
    "1. itertools.product --> pandas dataframe\n",
    "1. itertools.chain\n",
    "1. format strings\n",
    "1. tqdm\n",
    "1. `df.apply(lambda row: {id}_{abundance}_k{ksize}.format(**row), axis=1)`\n",
    "1. git branch\n",
    "1. grep\n",
    "1. awk\n",
    "1. sed\n",
    "1. wc -l\n",
    "1. make tidy df, chain pandas commands: `df.reset_index().stack().reset_index()`\n",
    "1. save as parquet\n",
    "1. read lots of csv files and concat, save as parquet\n",
    "1. screen/tmux\n",
    "1. read csvs from s3 (s3fs)\n",
    "1. seaborn facetgrid\n",
    "1. hover-able stuff with holoviews\n",
    "1. aliases (ll, exa)\n",
    "1. soft links (`mv ~/anaconda /mnt/data/anaconda && sudo ln -s /mnt/data/anaconda ~/anaconda`)\n",
    "1. tunnel jupyter notebook\n",
    "1. `watch --differences -n 60 check_reflow_status.py`\n",
    "1. `tail -n 20 log* | less -S`\n",
    "1. xargs\n",
    "1. `grep canceled listbatch.txt |cut -f 1 -d ' ' | sed 's/^/log./g' | xargs tail -n 20 - | less`\n",
    "1. markdown cells in jupyter notebook\n",
    "1. `pd.options.display.max_colwidth = 500`\n",
    "1. kwargs=dict(), `**kwargs`\n",
    "1. \n",
    "```\n",
    "✘  Fri 21 Sep - 01:29  ~ \n",
    "  mv ~/anaconda /mnt/data/anaconda\n",
    "\n",
    " Fri 21 Sep - 01:31  ~ \n",
    "  ln -s /mnt/data/anaconda ~/anaconda\n",
    "```\n",
    "1. regex, regex101, pandas extract\n",
    "1. \n",
    "```\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```\n",
    "1. write python file in jupyter, import it\n",
    "1. groupby\n",
    "1. %debug\n",
    "1. join\n",
    "1. colorbrewer\n",
    "1. download fastqs from SRA with reflow\n",
    "1. `diff <(gunzip -c tick_1_S1_first1Mreads_R1_adapterremoval_trimmed.fastq.gz) <(gunzip -c tick_1_S1_R1_001_first1Mreads_fastp_trimmed.fastq.gz)`\n",
    "1. pbpaste/pbcopy\n",
    "1. `gist --private` command line \n",
    "1. jupter notebook keystrokes: \n",
    "    - Ctrl-M-A add cell above\n",
    "    - Ctrl-M-B add cell below\n",
    "    - Ctrl-M-d d delete cell\n",
    "    - Ctrl-M-i interrupt\n",
    "    - Ctrl-M-0 restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE tabula-muris-k21-dna/\r\n",
      "                           PRE tabula-muris-k21-protein/\r\n",
      "                           PRE tabula-muris-k27-dna/\r\n",
      "                           PRE tabula-muris-k27-protein/\r\n",
      "                           PRE tabula-muris-k33-dna/\r\n",
      "                           PRE tabula-muris-k33-protein/\r\n",
      "                           PRE tabula-muris-k51-dna/\r\n",
      "                           PRE tabula-muris-k51-protein/\r\n"
     ]
    }
   ],
   "source": [
    "prefix = 's3://olgabot-maca/facs/sourmash_index_all'\n",
    "txt = 'sourmash_databases.txt'\n",
    "\n",
    "! aws s3 ls $prefix/ > $txt\n",
    "! cat $txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 ls s3://olgabot-maca/facs/sourmash_compare/ > aws_s3_ls_tabula_muris_compare.txt\n",
    "\n",
    "aws_s3_ls = pd.read_table('aws_s3_ls_tabula_muris_compare.txt', \n",
    "                          delim_whitespace=True, header=None, \n",
    "                          names=['date', 'time', 'bytes', 'basename'])\n",
    "print(aws_s3_ls.shape)\n",
    "aws_s3_ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases = pd.read_table(txt, delim_whitespace=True, header=None, names=['is_prefix', 'database_name'])\n",
    "databases['database_name'] = databases['database_name'].str.strip('/')\n",
    "databases = databases.drop('is_prefix', axis=1)\n",
    "databases['ksize'] = databases['database_name'].str.extract('k(\\d+)').astype(int)\n",
    "databases['sequence_to_compare'] = databases['database_name'].map(lambda x: x.split('-')[-1])\n",
    "databases['database'] = databases['database_name'].map(lambda x: f'{prefix}/{x}/{x}/')\n",
    "databases = databases.set_index('database_name')\n",
    "databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
